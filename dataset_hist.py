from torch.utils.data import Dataset
import cv2
import random
import torch
from tqdm import tqdm
import os
import numpy as np
import sys
from matplotlib import pyplot as plt
from torch.utils.data import DataLoader


def arrayToHist(grayArray, bins=256):
    # 将灰度数组映射为直方图字典,bins表示灰度的数量级
    if (len(grayArray.shape) != 2):
        print("length error")
        return None
    h, w = grayArray.shape
    hist = {}
    for k in range(bins):
        hist[k] = 0
    for i in range(h):
        for j in range(w):
            if (hist.get(grayArray[i][j]) is None):
                hist[grayArray[i][j]] = 0
            hist[grayArray[i][j]] += 1
    # normalize
    n = w * h
    for key in hist.keys():
        hist[key] = float(hist[key]) / n
    return hist


def equalization(grayArray, h_s, bins=256):
    # 计算累计直方图计算出新的均衡化的图片，bins为灰度数,256
    # 计算累计直方图
    tmp = 0.0
    h_acc = h_s.copy()
    for i in range(256):
        tmp += h_s[i]
        h_acc[i] = tmp

    if (len(grayArray.shape) != 2):
        print("length error")
        return None

    h, w = grayArray.shape
    des = np.zeros((h, w), dtype=np.uint8)
    for i in range(h):
        for j in range(w):
            des[i][j] = int((bins - 1) * h_acc[grayArray[i][j]] + 0.5)
    return des


class REC_DATASET(Dataset):
    def __init__(self, source_paths, target_paths, patch_size, patch_num_per_img, fix_img_size, extract_random_patch,
                 augment):
        super(REC_DATASET, self).__init__()
        patches_info = []
        image_idx = 0
        for path in tqdm(source_paths):

            if fix_img_size is None:
                img = cv2.imread(path)
                if len(img.shape) == 2:
                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                h, w, _ = img.shape
            else:
                if not os.path.exists(path):
                    print('Image is not existed.', path)
                    sys.exit()
                h, w = fix_img_size

            if not (patch_size < h and patch_size < w):
                print('patch_size is not suitable.', path, patch_size, h, w, path)
                sys.exit()

            if patch_num_per_img > 1:
                if extract_random_patch == 0:
                    for _ in range(patch_num_per_img):
                        i = np.random.randint(0, h - patch_size)
                        j = np.random.randint(0, w - patch_size)
                        patches_info.append([image_idx, i, i + patch_size, j, j + patch_size])
                else:
                    patch_stride = patch_size // 2
                    patch_cnt = 0
                    for i in range(0, h - patch_size + 1, patch_stride):
                        if patch_cnt > patch_num_per_img:
                            break
                        for j in range(0, w - patch_size + 1, patch_stride):
                            if patch_cnt > patch_num_per_img:
                                break
                            patches_info.append([image_idx, i, i + patch_size, j, j + patch_size])
                            patch_cnt += 1
            else:
                i = h // 2 - patch_size // 2
                j = w // 2 - patch_size // 2
                patches_info.append([image_idx, i, i + patch_size, j, j + patch_size])

            image_idx += 1

        # random.shuffle(patches_info)

        self.source_paths = source_paths
        self.target_paths = target_paths
        self.patches_info = patches_info
        self.augment = augment

        self.H_gt_b = [0.238777920740741, 0.00741480222222222, 0.00519327481481482, 0.00419833333333333,
                       0.00334166444444444, 0.00285700814814815, 0.00242841259259259, 0.00214954888888889,
                       0.00182284814814815, 0.00147472888888889, 0.00120493851851852, 0.000977301481481482,
                       0.000941794074074074, 0.000705940000000000, 0.000620720000000000, 0.000625242222222222,
                       0.000555514074074074, 0.000530905185185185, 0.000543493333333333, 0.000475597777777778,
                       0.000486519259259259, 0.000446015555555556, 0.000423740000000000, 0.000423417037037037,
                       0.000446452592592593, 0.000472163703703704, 0.000427216296296296, 0.000383060000000000,
                       0.000388442222222222, 0.000395667407407407, 0.000403654074074074, 0.000402220000000000,
                       0.000368349629629630, 0.000337171111111111, 0.000386466666666667, 0.000329371851851852,
                       0.000324222222222222, 0.000328090370370370, 0.000362788148148148, 0.000332590370370370,
                       0.000311093333333333, 0.000352273333333333, 0.000302326666666667, 0.000301429629629630,
                       0.000297722222222222, 0.000294138518518519, 0.000291614814814815, 0.000298871111111111,
                       0.000287432592592593, 0.000293298518518519, 0.000311206666666667, 0.000400903703703704,
                       0.000281769629629630, 0.000277200740740741, 0.000269613333333333, 0.000271930370370370,
                       0.000269214074074074, 0.000330785185185185, 0.000265440740740741, 0.000263897037037037,
                       0.000261710370370370, 0.000270058518518519, 0.000303072592592593, 0.000320790370370370,
                       0.000286381481481481, 0.000256385925925926, 0.000254692592592593, 0.000256520740740741,
                       0.000252825185185185, 0.000270177777777778, 0.000250661481481482, 0.000248814074074074,
                       0.000249308888888889, 0.000245908148148148, 0.000244478518518519, 0.000246653333333333,
                       0.000260866666666667, 0.000259766666666667, 0.000244685185185185, 0.000241457777777778,
                       0.000241091111111111, 0.000241224444444444, 0.000240285185185185, 0.000240409629629630,
                       0.000243637777777778, 0.000240391851851852, 0.000237237777777778, 0.000236282962962963,
                       0.000234002222222222, 0.000232160000000000, 0.000232592592592593, 0.000234243703703704,
                       0.000230561481481482, 0.000228549629629630, 0.000228936296296296, 0.000226196296296296,
                       0.000225396296296296, 0.000222865185185185, 0.000226031851851852, 0.000222260000000000,
                       0.000222946666666667, 0.000224843703703704, 0.000338958518518519, 0.000224904444444444,
                       0.000220347407407407, 0.000220491111111111, 0.000220362222222222, 0.000223338518518519,
                       0.000219240740740741, 0.000222785185185185, 0.000219888148148148, 0.000218668888888889,
                       0.000227885925925926, 0.000246838518518519, 0.000215339259259259, 0.000215776296296296,
                       0.000210700000000000, 0.000212918518518519, 0.000210046666666667, 0.000209937777777778,
                       0.000209357037037037, 0.000219584444444444, 0.000206414814814815, 0.000207165185185185,
                       0.000202904444444444, 0.000201757037037037, 0.000202339259259259, 0.000216931851851852,
                       0.000206167407407407, 0.000203371111111111, 0.000198969629629630, 0.000198991111111111,
                       0.000197955555555556, 0.000194922962962963, 0.000197142222222222, 0.000195049629629630,
                       0.000193154814814815, 0.000192231851851852, 0.000191753333333333, 0.000192774814814815,
                       0.000189626666666667, 0.000188622222222222, 0.000187360000000000, 0.000186787407407407,
                       0.000188526666666667, 0.000185896296296296, 0.000184808148148148, 0.000182274814814815,
                       0.000195554074074074, 0.000183417037037037, 0.000181553333333333, 0.000178220000000000,
                       0.000179577777777778, 0.000182972592592593, 0.000181298518518519, 0.000178207407407407,
                       0.000178188888888889, 0.000176206666666667, 0.000174019259259259, 0.000177431851851852,
                       0.000177018518518519, 0.000174058518518519, 0.000172798518518519, 0.000174854074074074,
                       0.000171748148148148, 0.000173685185185185, 0.000173153333333333, 0.000171955555555556,
                       0.000172438518518519, 0.000172374814814815, 0.000171825185185185, 0.000170752592592593,
                       0.000170303703703704, 0.000171015555555556, 0.000169543703703704, 0.000169640000000000,
                       0.000170462222222222, 0.000172019259259259, 0.000170976296296296, 0.000177088888888889,
                       0.000169166666666667, 0.000170268888888889, 0.000170967407407407, 0.000170136296296296,
                       0.000171037777777778, 0.000168525925925926, 0.000170737037037037, 0.000169242222222222,
                       0.000177966666666667, 0.000170670370370370, 0.000166709629629630, 0.000170773333333333,
                       0.000165956296296296, 0.000165797037037037, 0.000166451851851852, 0.000165690370370370,
                       0.000163678518518519, 0.000164642962962963, 0.000164806666666667, 0.000164677777777778,
                       0.000173543703703704, 0.000163042962962963, 0.000165250370370370, 0.000165627407407407,
                       0.000173319259259259, 0.000163865185185185, 0.000165163703703704, 0.000164712592592593,
                       0.000162828148148148, 0.000184317777777778, 0.000194756296296296, 0.000177791111111111,
                       0.000163050370370370, 0.000163088888888889, 0.000168220740740741, 0.000164668888888889,
                       0.000164000000000000, 0.000165575555555556, 0.000166846666666667, 0.000167201481481481,
                       0.000166517777777778, 0.000168408148148148, 0.000168431851851852, 0.000168951851851852,
                       0.000173516296296296, 0.000171945185185185, 0.000171700740740741, 0.000174600000000000,
                       0.000181924444444444, 0.000169172592592593, 0.000169554814814815, 0.000172226666666667,
                       0.000171549629629630, 0.000172227407407407, 0.000173112592592593, 0.000172180000000000,
                       0.000174861481481481, 0.000178614074074074, 0.000178632592592593, 0.000183760740740741,
                       0.000179028148148148, 0.000187851851851852, 0.000188014814814815, 0.000187478518518519,
                       0.000188920000000000, 0.000200037037037037, 0.000200021481481482, 0.000205505925925926,
                       0.000209175555555556, 0.000214502962962963, 0.000220196296296296, 0.000236413333333333,
                       0.000241814074074074, 0.000251577777777778, 0.000284157037037037, 0.00369921333333333]
        self.H_gt_g = [0.238490868888889, 0.00762936518518519, 0.00522866074074074, 0.00418453259259259,
                       0.00334469111111111, 0.00284575185185185, 0.00248194296296296, 0.00215107851851852,
                       0.00182474740740741, 0.00147661481481481, 0.00120093629629630, 0.000986110370370370,
                       0.000859777777777778, 0.000698648148148148, 0.000622069629629630, 0.000654183703703704,
                       0.000577340740740741, 0.000523113333333333, 0.000493503703703704, 0.000477986666666667,
                       0.000491771851851852, 0.000490335555555556, 0.000453749629629630, 0.000452112592592593,
                       0.000417674074074074, 0.000528100000000000, 0.000410302222222222, 0.000373985185185185,
                       0.000395936296296296, 0.000360734074074074, 0.000399571111111111, 0.000406244444444444,
                       0.000371371851851852, 0.000335350370370370, 0.000384770370370370, 0.000329572592592593,
                       0.000322758518518519, 0.000328754074074074, 0.000359513333333333, 0.000313767407407407,
                       0.000311206666666667, 0.000347653333333333, 0.000303031111111111, 0.000299105185185185,
                       0.000296541481481481, 0.000291065925925926, 0.000295278518518519, 0.000299274814814815,
                       0.000295693333333333, 0.000293541481481482, 0.000308457037037037, 0.000367877037037037,
                       0.000284208888888889, 0.000302857037037037, 0.000271181481481482, 0.000272279259259259,
                       0.000269671111111111, 0.000292994814814815, 0.000272334814814815, 0.000264037037037037,
                       0.000266026666666667, 0.000270045185185185, 0.000303548888888889, 0.000319970370370370,
                       0.000279680000000000, 0.000256625185185185, 0.000253782222222222, 0.000253751851851852,
                       0.000248863703703704, 0.000249661481481482, 0.000247323703703704, 0.000247204444444444,
                       0.000253825925925926, 0.000247245185185185, 0.000245097777777778, 0.000245014814814815,
                       0.000247005925925926, 0.000252090370370370, 0.000241529629629630, 0.000238746666666667,
                       0.000237673333333333, 0.000236356296296296, 0.000235915555555556, 0.000236437037037037,
                       0.000238314814814815, 0.000234734814814815, 0.000232414814814815, 0.000232648148148148,
                       0.000231215555555556, 0.000235670370370370, 0.000229649629629630, 0.000228626666666667,
                       0.000227109629629630, 0.000225610370370370, 0.000226542222222222, 0.000224275555555556,
                       0.000224384444444444, 0.000222965185185185, 0.000225628888888889, 0.000222692592592593,
                       0.000221672592592593, 0.000225625925925926, 0.000228818518518519, 0.000222730370370370,
                       0.000219100740740741, 0.000219286666666667, 0.000220579259259259, 0.000217442962962963,
                       0.000217838518518519, 0.000218351851851852, 0.000219882222222222, 0.000255234814814815,
                       0.000216234074074074, 0.000216168148148148, 0.000214866666666667, 0.000215345185185185,
                       0.000209752592592593, 0.000212286666666667, 0.000210571851851852, 0.000209444444444444,
                       0.000209008888888889, 0.000205345185185185, 0.000205902962962963, 0.000206831111111111,
                       0.000203851111111111, 0.000202516296296296, 0.000205995555555556, 0.000228911851851852,
                       0.000209008148148148, 0.000201199259259259, 0.000199920740740741, 0.000199268148148148,
                       0.000199291111111111, 0.000196122222222222, 0.000198328888888889, 0.000195840000000000,
                       0.000194334074074074, 0.000193394074074074, 0.000192169629629630, 0.000192377777777778,
                       0.000189893333333333, 0.000188869629629630, 0.000188269629629630, 0.000189204444444444,
                       0.000191403703703704, 0.000186673333333333, 0.000185700740740741, 0.000184497777777778,
                       0.000197243703703704, 0.000185865925925926, 0.000183342222222222, 0.000181758518518519,
                       0.000187173333333333, 0.000245866666666667, 0.000189485925925926, 0.000183697777777778,
                       0.000183349629629630, 0.000180525185185185, 0.000179362222222222, 0.000181318518518519,
                       0.000181361481481481, 0.000180475555555556, 0.000179237777777778, 0.000181200740740741,
                       0.000178375555555556, 0.000181481481481482, 0.000179960000000000, 0.000179332592592593,
                       0.000178933333333333, 0.000177624444444444, 0.000177704444444444, 0.000173905185185185,
                       0.000173914074074074, 0.000173044444444444, 0.000169942962962963, 0.000170645925925926,
                       0.000170718518518519, 0.000173289629629630, 0.000170110370370370, 0.000168848148148148,
                       0.000168215555555556, 0.000170096296296296, 0.000170065925925926, 0.000167878518518519,
                       0.000169553333333333, 0.000168066666666667, 0.000170491851851852, 0.000167234814814815,
                       0.000168332592592593, 0.000169020740740741, 0.000163827407407407, 0.000169638518518519,
                       0.000169180740740741, 0.000166622222222222, 0.000166635555555556, 0.000166062222222222,
                       0.000164232592592593, 0.000166814074074074, 0.000168094074074074, 0.000168460740740741,
                       0.000167034074074074, 0.000164617777777778, 0.000166893333333333, 0.000166193333333333,
                       0.000176044444444444, 0.000166311851851852, 0.000166488148148148, 0.000164152592592593,
                       0.000164396296296296, 0.000165763703703704, 0.000168065185185185, 0.000166227407407407,
                       0.000163933333333333, 0.000166581481481481, 0.000170494814814815, 0.000167059259259259,
                       0.000166050370370370, 0.000179234814814815, 0.000169017777777778, 0.000169491111111111,
                       0.000167796296296296, 0.000168556296296296, 0.000169572592592593, 0.000169850370370370,
                       0.000177075555555556, 0.000174585925925926, 0.000173448148148148, 0.000177525185185185,
                       0.000183111851851852, 0.000171706666666667, 0.000171108888888889, 0.000175750370370370,
                       0.000172642962962963, 0.000173167407407407, 0.000174485185185185, 0.000172782962962963,
                       0.000173801481481482, 0.000178308888888889, 0.000178009629629630, 0.000183001481481482,
                       0.000178366666666667, 0.000190857037037037, 0.000191357777777778, 0.000189414074074074,
                       0.000189774814814815, 0.000194737777777778, 0.000207783703703704, 0.000207062962962963,
                       0.000216129629629630, 0.000214364444444444, 0.000219477037037037, 0.000234614814814815,
                       0.000240200740740741, 0.000249074074074074, 0.000263878518518519, 0.00382041925925926]
        self.H_gt_r = [0.238680747407407, 0.00760920444444444, 0.00521572666666667, 0.00421119185185185,
                       0.00335770148148148, 0.00284501851851852, 0.00246533037037037, 0.00218071851851852,
                       0.00179719703703704, 0.00148214370370370, 0.00119775629629630, 0.000982190370370370,
                       0.000835216296296296, 0.000694482222222222, 0.000626846666666667, 0.000610931851851852,
                       0.000554172592592593, 0.000520303703703704, 0.000496225185185185, 0.000495381481481482,
                       0.000490175555555556, 0.000484776296296296, 0.000428489629629630, 0.000420613333333333,
                       0.000419280740740741, 0.000461333333333333, 0.000392591111111111, 0.000370840000000000,
                       0.000391282962962963, 0.000377394074074074, 0.000396477037037037, 0.000391284444444444,
                       0.000368114074074074, 0.000346865185185185, 0.000400302222222222, 0.000328223703703704,
                       0.000336731851851852, 0.000327225925925926, 0.000391201481481481, 0.000313727407407407,
                       0.000313576296296296, 0.000349657037037037, 0.000303054814814815, 0.000312415555555556,
                       0.000297439259259259, 0.000294569629629630, 0.000316202962962963, 0.000298905925925926,
                       0.000283767407407407, 0.000289717037037037, 0.000300949629629630, 0.000371140000000000,
                       0.000282670370370370, 0.000277342962962963, 0.000270906666666667, 0.000271782222222222,
                       0.000268482222222222, 0.000293843703703704, 0.000264256296296296, 0.000264805185185185,
                       0.000263270370370370, 0.000269247407407407, 0.000304422962962963, 0.000322665185185185,
                       0.000283017777777778, 0.000275564444444444, 0.000255755555555556, 0.000256684444444444,
                       0.000265221481481482, 0.000254471111111111, 0.000246266666666667, 0.000245657037037037,
                       0.000247286666666667, 0.000244167407407407, 0.000243011111111111, 0.000243488148148148,
                       0.000246964444444445, 0.000249031111111111, 0.000239556296296296, 0.000237216296296296,
                       0.000243213333333333, 0.000235082962962963, 0.000234665185185185, 0.000235211111111111,
                       0.000237912592592593, 0.000234086666666667, 0.000231992592592593, 0.000231708148148148,
                       0.000230077777777778, 0.000227718518518519, 0.000230405925925926, 0.000229068148148148,
                       0.000230978518518519, 0.000226492592592593, 0.000230692592592593, 0.000224257777777778,
                       0.000225422962962963, 0.000223045185185185, 0.000224967407407407, 0.000222158518518519,
                       0.000221636296296296, 0.000227848148148148, 0.000239043703703704, 0.000222074814814815,
                       0.000218229629629630, 0.000218961481481481, 0.000217074074074074, 0.000216056296296296,
                       0.000216302222222222, 0.000216962222222222, 0.000216949629629630, 0.000215687407407407,
                       0.000214432592592593, 0.000215283703703704, 0.000215113333333333, 0.000252594074074074,
                       0.000210146666666667, 0.000212012592592593, 0.000210038518518519, 0.000209262222222222,
                       0.000216082962962963, 0.000204029629629630, 0.000204275555555556, 0.000204853333333333,
                       0.000201496296296296, 0.000199571851851852, 0.000200414814814815, 0.000216856296296296,
                       0.000201377037037037, 0.000197538518518519, 0.000197378518518519, 0.000196444444444444,
                       0.000196912592592593, 0.000193708148148148, 0.000195720740740741, 0.000193784444444444,
                       0.000192875555555556, 0.000191974814814815, 0.000190931851851852, 0.000191920740740741,
                       0.000190692592592593, 0.000188832592592593, 0.000187464444444444, 0.000187522222222222,
                       0.000188645185185185, 0.000186614814814815, 0.000186511111111111, 0.000183692592592593,
                       0.000196417037037037, 0.000184281481481481, 0.000182204444444444, 0.000179051111111111,
                       0.000180626666666667, 0.000184808888888889, 0.000180055555555556, 0.000179365925925926,
                       0.000179160000000000, 0.000176694074074074, 0.000174516296296296, 0.000176735555555556,
                       0.000177211851851852, 0.000173854814814815, 0.000172982962962963, 0.000174548888888889,
                       0.000170611111111111, 0.000172622222222222, 0.000171894074074074, 0.000170822962962963,
                       0.000170132592592593, 0.000171574074074074, 0.000170590370370370, 0.000169812592592593,
                       0.000170628148148148, 0.000174420740740741, 0.000172888148148148, 0.000172517777777778,
                       0.000172317777777778, 0.000174664444444444, 0.000174076296296296, 0.000171760000000000,
                       0.000170939259259259, 0.000173062962962963, 0.000173159259259259, 0.000171322962962963,
                       0.000169984444444444, 0.000164584444444444, 0.000166310370370370, 0.000164020000000000,
                       0.000165316296296296, 0.000177237777777778, 0.000164138518518519, 0.000168134074074074,
                       0.000164248148148148, 0.000164410370370370, 0.000165147407407407, 0.000164791111111111,
                       0.000162473333333333, 0.000164441481481481, 0.000167138518518519, 0.000164942222222222,
                       0.000164759259259259, 0.000162664444444444, 0.000165002962962963, 0.000164537037037037,
                       0.000226954074074074, 0.000165011851851852, 0.000167302962962963, 0.000164291851851852,
                       0.000163677777777778, 0.000165096296296296, 0.000167595555555556, 0.000165587407407407,
                       0.000163562222222222, 0.000164969629629630, 0.000170282962962963, 0.000167141481481482,
                       0.000165999259259259, 0.000179831851851852, 0.000169420740740741, 0.000169994074074074,
                       0.000168791111111111, 0.000169393333333333, 0.000170394814814815, 0.000170643703703704,
                       0.000176731851851852, 0.000175719259259259, 0.000174431111111111, 0.000178817037037037,
                       0.000184923703703704, 0.000174639259259259, 0.000180422962962963, 0.000182341481481481,
                       0.000175022222222222, 0.000174945185185185, 0.000180862962962963, 0.000174648888888889,
                       0.000175406666666667, 0.000179676296296296, 0.000179493333333333, 0.000184857037037037,
                       0.000183611851851852, 0.000191601481481481, 0.000191908148148148, 0.000199013333333333,
                       0.000192549629629630, 0.000196232592592593, 0.000201982962962963, 0.000207360740740741,
                       0.000210503703703704, 0.000215928888888889, 0.000221392592592593, 0.000237062222222222,
                       0.000249281481481482, 0.000253128148148148, 0.000272977777777778, 0.00391644000000000]

    def __len__(self):
        return len(self.patches_info)

    def __getitem__(self, idx):
        image_idx = self.patches_info[idx][0]
        patch_cord_h0 = self.patches_info[idx][1]
        patch_cord_h1 = self.patches_info[idx][2]
        patch_cord_w0 = self.patches_info[idx][3]
        patch_cord_w1 = self.patches_info[idx][4]

        source_image = cv2.imread(self.source_paths[image_idx])
        target_image = cv2.imread(self.target_paths[image_idx])

        source_patch = source_image[patch_cord_h0:patch_cord_h1, patch_cord_w0:patch_cord_w1, :]
        target_patch = target_image[patch_cord_h0:patch_cord_h1, patch_cord_w0:patch_cord_w1, :]

        if self.augment:
            if np.random.rand() < 0.5:
                np.flipud(source_patch)
                np.flipud(target_patch)
            if np.random.rand() < 0.5:
                np.fliplr(source_patch)
                np.fliplr(target_patch)
            if np.random.rand() < 0.5:
                np.flipud(source_patch)
                np.flipud(target_patch)
            if np.random.rand() < 0.5:
                np.rot90(source_patch, 1)
                np.rot90(target_patch, 1)
            if np.random.rand() < 0.5:
                np.rot90(source_patch, 1)
                np.rot90(target_patch, 1)

        source_patch = 255 - source_patch
        target_patch = 255 - target_patch

        source_patch[:, :, 0] = equalization(source_patch[:, :, 0], self.H_gt_b)
        source_patch[:, :, 1] = equalization(source_patch[:, :, 1], self.H_gt_g)
        source_patch[:, :, 2] = equalization(source_patch[:, :, 2], self.H_gt_r)
        source_patch = np.clip(source_patch, 0, 255)

        source_patch = source_patch / 255.0
        target_patch = target_patch / 255.0

        source_patch = torch.from_numpy(source_patch).permute(2, 0, 1).float()
        target_patch = torch.from_numpy(target_patch).permute(2, 0, 1).float()

        return source_patch, target_patch


def extract_path_pairs(source_paths_txt, target_paths_txt, shuffle=False):
    with open(source_paths_txt, 'r') as f:
        lines = f.readlines()
        source_paths = [i.strip() for i in lines]

    with open(target_paths_txt, 'r') as f:
        lines = f.readlines()
        target_paths = [i.strip() for i in lines]

    if shuffle:
        random.seed(0)
        random.shuffle(source_paths)
        random.seed(0)
        random.shuffle(target_paths)

    return source_paths, target_paths


if __name__ == '__main__':
    source_paths_test_txt = '/data/datasets/TEXT_DEBLUR/blur_test.txt'
    target_paths_test_txt = '/data/datasets/TEXT_DEBLUR/gt_test.txt'
    source_paths_test, target_paths_test = extract_path_pairs(source_paths_test_txt, target_paths_test_txt,
                                                              shuffle=False)
    print('dataset test images num:', len(source_paths_test))

    patch_size_test = 192
    patch_num_per_img_test = 1
    fix_img_size_test = (200, 200)
    extract_random_patch_test = False
    augment = False

    dataset_test = REC_DATASET(source_paths_test, target_paths_test, patch_size_test, patch_num_per_img_test,
                               fix_img_size_test, extract_random_patch_test, augment)
    loader_test = DataLoader(dataset=dataset_test, num_workers=0, batch_size=8, shuffle=False)

    criterion = torch.nn.L1Loss()

    for i, (source_tensor, target_tensor) in enumerate(loader_test):
        print(source_tensor.shape, target_tensor.shape, torch.min(source_tensor), torch.max(source_tensor))

        source_tensor, target_tensor = source_tensor.cuda(), target_tensor.cuda()

        loss = criterion(source_tensor, target_tensor)

        print(loss.shape, type(loss), loss.dtype, loss.requires_grad, loss.item())

        source_b = (np.array(source_tensor[0, 0, :, :].cpu()) * 255).astype('uint8')
        target_b = (np.array(target_tensor[0, 0, :, :].cpu()) * 255).astype('uint8')

        plt.figure()
        plt.subplot(1, 2, 1)
        plt.imshow(source_b)
        plt.subplot(1, 2, 2)
        plt.imshow(target_b)
        plt.savefig('tmp/' + str(i) + '_hist.png')
